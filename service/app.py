import sys
import os
import streamlit as st
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from retrieval.retriever import retrieve_docs, build_context
from generation.generator import generate_answer, build_prompt
from generation.prompt import PROMPT_TEMPLATE
import dotenv
from langchain_openai import ChatOpenAI
import os
from evaluation.rag_evaluator import evaluate_rag_system
from transformers import AutoModelForSequenceClassification, AutoTokenizer
import torch

# --- 0. è·¯å¾„ä¸åŸºç¡€è®¾ç½® ---
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# ç¡®ä¿è·¯å¾„ä¸‹åŒ…å«è¿™äº›è‡ªå®šä¹‰æ¨¡å—
try:
    from retrieval.retriever import retrieve_docs, build_context
    from evaluation.rag_evaluator import evaluate_rag_system
except ImportError:
    pass

# ã€å®šä¹‰æ ¸å¿ƒå˜é‡ã€‘
WELCOME_MSG = "æˆ‘æ˜¯åŒ—äº¬äº¤é€šå¤§å­¦å­¦ç”Ÿæ‰‹å†Œå°åŠ©æ‰‹ï¼Œå¯ä»¥å¸®ä½ è§£ç­”æœ‰å…³å­¦ä¹ è§„ç« åˆ¶åº¦çš„é—®é¢˜ã€‚è¯·é—®æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"
# --- 1. é¡µé¢é…ç½®ä¸ UI ä¼˜åŒ– CSS ---
st.set_page_config(page_title="åŒ—äº¤å¤§å­¦ç”Ÿæ‰‹å†ŒåŠ©æ‰‹", page_icon="ğŸ«", layout="wide")

st.markdown("""
    <style>
        /* 1. å…¨å±€å­—ä½“ä¸ä¾§è¾¹æ èƒŒæ™¯ */
        html, body, [class*="st-"] {
            font-family: "PingFang SC", "Microsoft YaHei", sans-serif !important;
        }
        [data-testid="stSidebar"] {
            background-color: #003366;
        }

        /* 2. ä¾§è¾¹æ ç»„ä»¶é—´è·ä¼˜åŒ– */
        [data-testid="stSidebar"] [data-testid="stVerticalBlock"] {
            gap: 0.5rem !important;
        }

        /* 3. ç³»ç»Ÿæ¦‚å†µæè¿°æ¡†æ ·å¼ */
        .system-info-card {
            background-color: rgba(255, 255, 255, 0.05);
            border-radius: 12px;
            padding: 15px;
            margin: 10px 0 20px 0;
            border: 1px solid rgba(255, 255, 255, 0.1);
        }
        .system-info-card h3 {
            color: white !important;
            font-size: 1.1rem !important;
            margin-bottom: 8px !important;
        }
        .system-info-card p {
            color: rgba(255, 255, 255, 0.8) !important;
            font-size: 0.9rem !important;
            line-height: 1.5 !important;
        }
        .tip-box {
            background-color: rgba(173, 216, 230, 0.1);
            border-radius: 8px;
            padding: 10px;
            margin-top: 10px;
            font-size: 0.85rem;
            color: #ADD8E6;
            border-left: 3px solid #ADD8E6;
        }

        /* 4. ä¾§è¾¹æ æ ‡é¢˜ */
        .sidebar-title {
            color: rgba(255, 255, 255, 0.6) !important;
            font-size: 0.85rem !important;
            font-weight: 600 !important;
            text-transform: uppercase;
            margin: 20px 0 8px 5px !important;
        }

        /* 5. æŒ‰é’®åŸºç¡€æ ·å¼ï¼šå½»åº•å»æ¡†ã€æ— èƒŒæ™¯ã€å…¨å®½åº¦ */
        [data-testid="stSidebar"] .stButton button {
            background-color: transparent !important;
            border: none !important;
            box-shadow: none !important;
            color: #ffffff !important;
            width: 100% !important;
            height: 42px !important;
            padding: 0px 15px !important;
            border-radius: 10px !important;
            display: flex !important;
            align-items: center !important;
            justify-content: flex-start !important;
            text-align: left !important;
            transition: all 0.2s;
        }

        /* 6. å¼€å¯æ–°å¯¹è¯æŒ‰é’®ä¸“å±åŠ ç²— */
        button[key="new_chat_btn"] {
            background-color: rgba(255, 255, 255, 0.1) !important;
            margin-bottom: 10px !important;
        }
        button[key="new_chat_btn"] p {
            font-weight: 700 !important;
        }

        /* 7. å†å²å¯¹è¯æŒ‰é’®æ–‡å­—ï¼šæº¢å‡ºçœç•¥ */
        [data-testid="stSidebar"] .stButton button div p {
            color: inherit !important;
            font-size: 0.95rem !important;
            margin: 0 !important;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }

        /* 8. é€‰ä¸­çŠ¶æ€é«˜äº®ï¼šDeepSeek æµ…è“é£æ ¼ */
        [data-testid="stSidebar"] .stButton button:hover {
            background-color: rgba(255, 255, 255, 0.1) !important;
        }

        /* åˆ†å‰²çº¿ */
        hr {
            margin: 20px 0 !important;
            opacity: 0.1 !important;
        }
    </style>
    """, unsafe_allow_html=True)


# --- 2. åˆå§‹åŒ–æ¨¡å‹ ---
@st.cache_resource
def init_models():
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-zh-v1.5",
        model_kwargs={'device': 'cpu'}
    )
    db_path = os.path.join(project_root, "chroma_db")
    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)

    dotenv.load_dotenv()
    llm = ChatOpenAI(model="gpt-4o-mini", streaming=True, temperature=0.3)

    rerank_model_name = "BAAI/bge-reranker-base"
    rerank_tokenizer = AutoTokenizer.from_pretrained(rerank_model_name)
    rerank_model = AutoModelForSequenceClassification.from_pretrained(
        rerank_model_name
    )
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    rerank_model.to(device)
    rerank_model.eval()
    return vector_db, llm, rerank_model, rerank_tokenizer


vector_db, llm, rerank_model, rerank_tokenizer = init_models()

# --- 3. çŠ¶æ€ç®¡ç† ---
if "sessions" not in st.session_state:
    st.session_state.sessions = [{"name": "æ–°å¯¹è¯", "messages": [{"role": "assistant", "content": WELCOME_MSG}]}]
if "active_session_idx" not in st.session_state:
    st.session_state.active_session_idx = 0
if "eval_buffer" not in st.session_state:
    st.session_state.eval_buffer = []

# --- 4. ä¾§è¾¹æ å†…å®¹ ---
with st.sidebar:
    # å­¦æ ¡ Logo
    st.image("https://www.bjtu.edu.cn/images/logo.png", use_container_width=True)

    # ç³»ç»Ÿæ¦‚å†µæè¿°å— (ä»¿ç…§å›¾ç‰‡)
    st.markdown("""
    <div class="system-info-card">
        <h3>ç³»ç»Ÿæ¦‚å†µ</h3>
        <p>æ¬¢è¿ä½¿ç”¨ï¼æœ¬åŠ©æ‰‹åŸºäº <b>GPT-4o / RAG</b> æ¶æ„ï¼Œä¸“é—¨ä¸ºæ‚¨è§£ç­”ã€Šå­¦ç”Ÿæ‰‹å†Œã€‹ç›¸å…³é—®é¢˜ã€‚</p>
        <div class="tip-box">
            ğŸ’¡ æç¤ºï¼šå…³äºç»©ç‚¹ã€å¥–å­¦é‡‘ã€å¤„åˆ†çš„è§„å®šï¼Œç³»ç»Ÿå·²æ·±åº¦å­¦ä¹ ã€‚
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ã€1. å¼€å¯æ–°å¯¹è¯ã€‘
    if st.button("âœ¨ å¼€å¯æ–°å¯¹è¯", key="new_chat_btn"):
        st.session_state.sessions.insert(0, {"name": "æ–°å¯¹è¯",
                                             "messages": [{"role": "assistant", "content": WELCOME_MSG}]})
        st.session_state.active_session_idx = 0
        st.rerun()

    # ã€2. å†å²å¯¹è¯åˆ—è¡¨ã€‘
    st.markdown('<p class="sidebar-title">æœ€è¿‘å¯¹è¯</p>', unsafe_allow_html=True)
    for idx, session in enumerate(st.session_state.sessions):
        is_active = (idx == st.session_state.active_session_idx)

        # é€‰ä¸­é«˜äº®é€»è¾‘
        if is_active:
            st.markdown(f"""<style>button[key="s_btn_{idx}"] {{ 
                background-color: #ADD8E6 !important; 
                color: #000000 !important; 
                font-weight: 600 !important; 
            }}</style>""", unsafe_allow_html=True)

        # ç§»é™¤äº†åˆ é™¤æŒ‰é’®åˆ—ï¼Œç›´æ¥å±•ç¤ºå…¨å®½å¯¹è¯æŒ‰é’®
        if st.button(session['name'], key=f"s_btn_{idx}"):
            st.session_state.active_session_idx = idx
            st.rerun()

    st.markdown("---")

    # ã€3. ç³»ç»Ÿæ“ä½œã€‘
    if st.button("ğŸ§¹ æ¸…ç©ºå½“å‰å¯¹è¯å†…å®¹", key="clear_chat_btn"):
        st.session_state.sessions[st.session_state.active_session_idx]["messages"] = [
            {"role": "assistant", "content": WELCOME_MSG}]
        st.rerun()

    if st.button("ğŸš€ è¿è¡Œ RAG è¯„ä¼°", key="run_eval_btn"):
        if st.session_state.eval_buffer:
            with st.spinner("è¯„ä¼°ä¸­..."):
                eval_result = evaluate_rag_system(st.session_state.eval_buffer, llm, vector_db._embedding_function)
                st.dataframe(eval_result.to_pandas(), use_container_width=True)

# --- 5. ä¸»ç•Œé¢æ¸²æŸ“ ---
current_session = st.session_state.sessions[st.session_state.active_session_idx]
st.title("ğŸ« åŒ—äº¬äº¤é€šå¤§å­¦å­¦ç”Ÿæ‰‹å†ŒåŠ©æ‰‹")

# èŠå¤©è®°å½•æ˜¾ç¤º
for msg in current_session["messages"]:
    icon = "ğŸ¤–" if msg["role"] == "assistant" else "ğŸ‘¤"
    with st.chat_message(msg["role"], avatar=icon):
        st.markdown(msg["content"])

# --- 6. èŠå¤©è¾“å…¥é€»è¾‘ ---
if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    if current_session["name"] == "æ–°å¯¹è¯":
        current_session["name"] = (prompt[:12] + '..') if len(prompt) > 12 else prompt

    current_session["messages"].append({"role": "user", "content": prompt})
    with st.chat_message("user", avatar="ğŸ‘¤"):
        st.markdown(prompt)

    with st.chat_message("assistant", avatar="ğŸ¤–"):
        # â‘  æ£€ç´¢
        # docs = retrieve_docs(vector_db,
        #                      prompt,
        #                      llm=llm,
        #                      use_multi_query=True,
        #                      use_hyde=True)
        docs = retrieve_docs(
            vector_db,
            prompt,
            llm=llm,
            k=30,
            fetch_k=60,
            use_multi_query=True,
            use_hyde=True,
            use_rrf=True,
            use_model_rerank=True,
            rerank_model=rerank_model,
            rerank_tokenizer=rerank_tokenizer,
            final_top_n=6,
        )
        # â‘¡ æ„å»ºä¸Šä¸‹æ–‡
        context = build_context(docs)

        def stream_response():
            full_prompt = build_prompt(PROMPT_TEMPLATE, prompt, context)
            for chunk in llm.stream(full_prompt):
                yield chunk.content

        # â‘¢ ç”Ÿæˆå›ç­”
        full_answer = st.write_stream(stream_response())
        current_session["messages"].append({"role": "assistant", "content": full_answer})

        # è®°å½•è¯„ä¼°æ•°æ®
        st.session_state.eval_buffer.append({
            "query": prompt,
            "answer": full_answer,
            "contexts": [d.page_content for d in docs]
        })
