import streamlit as st
import os
from langchain_ollama import OllamaLLM
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma

# --- 1. é¡µé¢é…ç½®ä¸è‡ªå®šä¹‰æ ·å¼ ---
st.set_page_config(page_title="åŒ—äº¤å¤§å­¦ç”Ÿæ‰‹å†ŒåŠ©æ‰‹", page_icon="ğŸ«", layout="centered")

# æ³¨å…¥ CSS ä¿®æ”¹ä¾§è¾¹æ é¢œè‰²ä¸ºæ·±è“è‰² (#003366 æ˜¯æ·±è“ç³»é¢œè‰²)
# --- 1. é¡µé¢é…ç½®ä¸è‡ªå®šä¹‰æ ·å¼ ---
st.set_page_config(page_title="åŒ—äº¤å¤§å­¦ç”Ÿæ‰‹å†ŒåŠ©æ‰‹", page_icon="ğŸ«", layout="centered")

# æ³¨å…¥ CSSï¼šä¿®æ”¹ä¾§è¾¹æ èƒŒæ™¯ä¸ºæ·±è“ï¼Œå¹¶ç¡®ä¿æŒ‰é’®æ–‡å­—ä¸ºé»‘è‰²
st.markdown("""
    <style>
        /* ä¿®æ”¹ä¾§è¾¹æ èƒŒæ™¯é¢œè‰² */
        [data-testid="stSidebar"] {
            background-color: #003366;
        }

        /* ä¿®æ”¹ä¾§è¾¹æ å†…çš„æ ‡é¢˜å’Œæ™®é€šæ–‡å­—ä¸ºç™½è‰² */
        [data-testid="stSidebar"] .stText, 
        [data-testid="stSidebar"] p, 
        [data-testid="stSidebar"] h1, 
        [data-testid="stSidebar"] h2, 
        [data-testid="stSidebar"] h3,
        [data-testid="stSidebar"] span {
            color: white !important;
        }

        /* æ ¸å¿ƒä¿®æ”¹ï¼šå¼ºåˆ¶ä¾§è¾¹æ æŒ‰é’®èƒŒæ™¯ä¸ºçº¯ç™½ï¼Œå­—ä½“é¢œè‰²ä¸ºé»‘è‰² */
        [data-testid="stSidebar"] .stButton button {
            background-color: #ffffff !important;
            color: #000000 !important;
            border: none;
            font-weight: bold;
        }

        /* é¼ æ ‡æ‚¬åœåœ¨æŒ‰é’®ä¸Šæ—¶çš„æ•ˆæœï¼ˆå¯é€‰ï¼Œå¢åŠ äº¤äº’æ„Ÿï¼‰ */
        [data-testid="stSidebar"] .stButton button:hover {
            background-color: #eeeeee !important;
            color: #000000 !important;
        }
    </style>
    """, unsafe_allow_html=True)

# --- 2. åŠ è½½åç«¯æ¨¡å‹ (ä¿æŒä¸å˜) ---
@st.cache_resource
def init_models():
    embeddings = HuggingFaceEmbeddings(
        model_name="BAAI/bge-small-zh-v1.5",
        model_kwargs={'device': 'cuda'}
    )
    db_path = "chroma_db"
    if not os.path.exists(db_path):
        return None, None
    vector_db = Chroma(persist_directory=db_path, embedding_function=embeddings)
    llm = OllamaLLM(model="deepseek-r1:8b", temperature=0.1)
    return vector_db, llm


vector_db, llm = init_models()

# --- 3. é¡µé¢æ ‡é¢˜ ---
st.title("ğŸ« åŒ—äº¬äº¤é€šå¤§å­¦")
st.subheader("å­¦ç”Ÿæ‰‹å†Œæ™ºèƒ½å’¨è¯¢åŠ©æ‰‹")
st.markdown("---")

# --- 4. ä¾§è¾¹æ å†…å®¹ (æ·±è“èƒŒæ™¯) ---
with st.sidebar:
    # å»ºè®®ï¼šå¦‚æœä½ æœ¬åœ°æœ‰æ ¡å¾½å›¾ç‰‡ï¼Œå¯ä»¥ç”¨ st.image("logo.png")
    # è¿™é‡Œå…ˆç”¨åŒ—äº¤å¤§å®˜ç½‘çš„é€æ˜åº•æ ¡å¾½é“¾æ¥ï¼ˆå¦‚æœé“¾æ¥å¤±æ•ˆè¯·æ›¿æ¢ä¸ºæœ¬åœ°è·¯å¾„ï¼‰
    st.image("https://www.bjtu.edu.cn/images/logo.png", use_container_width=True)

    st.markdown("### ç³»ç»Ÿæ¦‚å†µ")
    st.write("æ¬¢è¿ä½¿ç”¨ï¼æœ¬åŠ©æ‰‹åŸºäº DeepSeek-R1 æ¨ç†æ¨¡å‹ï¼Œä¸“é—¨ä¸ºæ‚¨è§£ç­”ã€Šå­¦ç”Ÿæ‰‹å†Œã€‹ç›¸å…³é—®é¢˜ã€‚")

    st.markdown("---")
    st.info("ğŸ’¡ **æç¤º**ï¼šå…³äºç»©ç‚¹ã€å¥–å­¦é‡‘ã€å¤„åˆ†çš„è§„å®šï¼Œç³»ç»Ÿå·²æ·±åº¦å­¦ä¹ ã€‚")

    if st.button("æ¸…ç©ºå¯¹è¯è®°å½•"):
        st.session_state.messages = []
        st.rerun()

# --- 5. å¯¹è¯é€»è¾‘ (ä¿æŒä¸å˜) ---
if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "åŒå­¦ä½ å¥½ï¼æˆ‘æ˜¯åŒ—äº¬äº¤é€šå¤§å­¦å­¦ç”Ÿæ‰‹å†Œå°åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ"}
    ]

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        with st.spinner("æ­£åœ¨æ£€ç´¢æ ¡è§„å¹¶æ€è€ƒ..."):
            try:
                docs = vector_db.max_marginal_relevance_search(prompt, k=6)
                context = "\n".join([d.page_content for d in docs])
                full_prompt = f"ä½ ç°åœ¨æ˜¯åŒ—äº¤å¤§åŠ©æ‰‹ã€‚èµ„æ–™ï¼š{context}\né—®é¢˜ï¼š{prompt}\nå›ç­”ï¼š"
                response = llm.invoke(full_prompt)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
            except Exception as e:
                st.error(f"å‡ºé”™å•¦: {e}")